{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "oY3HD3eyIyC7",
      "metadata": {
        "id": "oY3HD3eyIyC7"
      },
      "source": [
        "# Описание ДЗ1."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rRly-JkgJOo_",
      "metadata": {
        "id": "rRly-JkgJOo_"
      },
      "source": [
        "На основе семинара 1 предложите 2 метода улучшения построения эмбеддингов вопросов на основе word vectors.\n",
        "\n",
        "За задание можно получить максимум 10 баллов.\n",
        "\n",
        "За каждый метод можно получить максимум 5 баллов.\n",
        "Разбалловка:\n",
        "*   Воспроизводимость и читабельность кода - 1 балл.\n",
        "*   Корректность метода - 1 балл.\n",
        "*   Описание метода в техническом отчете - 2 балла.\n",
        "*   Иновационность - 1 балл.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b09d7a19-5848-43f4-9d91-f35d4e8614b0",
      "metadata": {
        "id": "b09d7a19-5848-43f4-9d91-f35d4e8614b0"
      },
      "source": [
        "# 1. Информация о сабмите"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc8a4e09-62cc-43fd-a7a7-3e9d55ec13b2",
      "metadata": {
        "id": "cc8a4e09-62cc-43fd-a7a7-3e9d55ec13b2"
      },
      "source": [
        "Щербаков Игорь Андреевич"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1af498ab-3c00-4d36-a962-c947862fede8",
      "metadata": {
        "id": "1af498ab-3c00-4d36-a962-c947862fede8"
      },
      "source": [
        "# 2. Технический отчет"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c327f43e-ed30-4279-bba2-a97b2f8ef9e3",
      "metadata": {
        "id": "c327f43e-ed30-4279-bba2-a97b2f8ef9e3"
      },
      "source": [
        "***Введите сюда** подробное описание предложенных методов и экспериментов, с помощью которых вы пришли именно к выбору этих методов. НЕ вставляйте код в эту часть. Описание должно состоять минимум из 2-4 абзацев и содержать следующее: тип модели, параметры, как вы выбрали параметры, какие дальнейшие модификации готовых решений и т.д. вы использовали. Сюда можно включить, например, некоторые хитрости вашей предварительной обработки, описание моделей и мотивацию их использования, описание деталей процесса обучения. Если нужно, вставьте сюда графики, математические формулы.*\n",
        "\n",
        "*Балл за «инновационность» будет присваиваться на основе содержания этой части. Если ваше отличие от бейзлайна это просто почистить тексты от стоп-слов или поменять одну базовую модель для построения word embeddings на другую, этот балл будет 0. Пробуйте разные подходы, модели, экспериментируйте с предварительной обработкой, параметрами и т. д. Можно переопределить уже существующий подход. Это нормально, что некоторые из ваших экспериментов не сработали так, как вы ожидали. Покажите нам, что вы проявили творческий подход и провели несколько экспериментов.*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "837fbc4d",
      "metadata": {},
      "source": [
        "<h2>Возможные шаги</h2>\n",
        "Какие шаги были бы возможны:\n",
        "<ul> 1. Предобработка данных х</ul>\n",
        "<ul> 2. Подбор модели</ul>\n",
        "<ul> 3. Подбор параметров модели</ul>\n",
        "<ul> 4. Эксперименты с эмбедингами слов (добавление доп размерностей с новой информацией)</ul>\n",
        "<ul> 5. Изменеиение способа получения представления фразы на основе представлений слов</ul>\n",
        "<ul> 6. Модификация алгоритмов поиска похожих: повышение качества и скорости</ul>\n",
        "\n",
        "\n",
        "Подбор разных моделей и их параметров, кажется весьма обыденным, поэтому в этом ноутбуке рассмотрим следующщие подходы: предобработку данных, дополнительные размерности в эмбединг слова, представление фразы на основе слов.\n",
        "\n",
        "<h2>Предпринятые шаги</h2>\n",
        "<h3>Предобработка</h3>\n",
        "В качестве дополнитльной предобработки были добавлены:\n",
        "<li>Удаление стоп слов\n",
        "<li> Алгоритм поиска похожих заменн]н на реализацию в FAISS, что позволило многократно ускорить поиск и повысить его релевантность \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "194fecf1-e044-4210-a54b-aefbf4b4eebe",
      "metadata": {
        "id": "194fecf1-e044-4210-a54b-aefbf4b4eebe"
      },
      "source": [
        "# 3. *Code*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a33ff9bd-62c6-4a63-8600-b1651420fee1",
      "metadata": {
        "id": "a33ff9bd-62c6-4a63-8600-b1651420fee1"
      },
      "source": [
        "*Введите сюда весь код, использованный для получения результатов. Добавьте несколько комментариев и подразделов для навигации по вашему решению.*\n",
        "\n",
        "*В этой части вам предстоит самостоятельно разработать решение задачи и предоставить воспроизводимый код:*\n",
        "- *Использование Python 3;*\n",
        "- *Содержит код для установки всех зависимостей;*\n",
        "- *Содержит код для загрузки всех используемых наборов данных*;\n",
        "- *Содержит код для воспроизведения ваших результатов (другими словами, если проверяющий загрузит ваш блокнот, он сможет выполнить код по ячейкам и получить результаты эксперимента, как описано в разделе методологии)*.\n",
        "\n",
        "\n",
        "*В результате ваш код будет оценен по следующим критериям:*\n",
        "- ***Читаемость**: ваш код должен быть хорошо структурирован, желательно с указанием частей вашего подхода (предварительная обработка, обучение модели, тестирование модели и т. д.).*\n",
        "- ***Воспроизводимость**: ваш код должен воспроизводиться без ошибок в режиме «Выполнить все» (получение экспериментальной части).*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b3c19fa-f883-4675-9506-85c4f02f0af9",
      "metadata": {
        "id": "1b3c19fa-f883-4675-9506-85c4f02f0af9"
      },
      "source": [
        "## 3.1 Импорт библиотек"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "82a7f821",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Установка бибилотек в окружение\n",
        "!pip install -q -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "9RQzpKJkLczr",
      "metadata": {
        "id": "9RQzpKJkLczr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "import gensim.downloader as api"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "791dc0e7-337d-46ad-96a3-543a732f19e2",
      "metadata": {
        "id": "791dc0e7-337d-46ad-96a3-543a732f19e2"
      },
      "source": [
        "## 3.2 Загрузка данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "cdce2db4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-05-26 10:25:01--  https://raw.githubusercontent.com/Falconwatch/llm_course/main/HW1/quora.txt\n",
            "Распознаётся raw.githubusercontent.com (raw.githubusercontent.com)… 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Подключение к raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... соединение установлено.\n",
            "HTTP-запрос отправлен. Ожидание ответа… 200 OK\n",
            "Длина: 33813903 (32M) [text/plain]\n",
            "Сохранение в: «./quora.txt»\n",
            "\n",
            "./quora.txt         100%[===================>]  32,25M  10,4MB/s    за 3,1s    \n",
            "\n",
            "2024-05-26 10:25:04 (10,4 MB/s) - «./quora.txt» сохранён [33813903/33813903]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# download the data:\n",
        "\n",
        "#!wget https://www.dropbox.com/s/obaitrix9jyu84r/quora.txt?dl=1 -O ./quora.txt\n",
        "#!wget https://yadi.sk/i/BPQrUu1NaTduEw -O ./quora.txt\n",
        "\n",
        "!wget https://raw.githubusercontent.com/Falconwatch/llm_course/main/HW1/quora.txt -O ./quora.txt\n",
        "\n",
        "data = np.array(list(open(\"./quora.txt\", encoding=\"utf-8\")))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23773d4e-e8d7-4e56-9610-4ee61b38c65a",
      "metadata": {
        "id": "23773d4e-e8d7-4e56-9610-4ee61b38c65a"
      },
      "source": [
        "## 3.3. Модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "6bbbe278",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /Users/igor/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "dec65766",
      "metadata": {},
      "outputs": [],
      "source": [
        "STOP_WORDS = set(stopwords.words('english')) \n",
        "TOKENIZER = WordPunctTokenizer()\n",
        "MODEL = api.load('glove-twitter-100')\n",
        "\n",
        "#model = FastText.load_fasttext_format('wiki.simple')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "-ySx_n28KGAX",
      "metadata": {
        "id": "-ySx_n28KGAX"
      },
      "outputs": [],
      "source": [
        "def get_phrase_embedding(phrase):\n",
        "    \"\"\"\n",
        "    Convert phrase to a vector by aggregating it's word embeddings. See description above.\n",
        "    \"\"\"\n",
        "    # 1. lowercase phrase\n",
        "    # 2. tokenize phrase\n",
        "    # 3. average word vectors for all words in tokenized phrase\n",
        "    # skip words that are not in model's vocabulary\n",
        "    # if all words are missing from vocabulary, return zeros\n",
        "\n",
        "    vector = np.zeros([MODEL.vector_size], dtype='float32')\n",
        "    word_vectors = []\n",
        "\n",
        "    data_tok = TOKENIZER.tokenize(phrase.lower())\n",
        "    word_vectors = np.array([MODEL.get_vector(word) for word in data_tok \n",
        "                             if (word in MODEL.key_to_index.keys()) and (word not in STOP_WORDS)])\n",
        "\n",
        "    if word_vectors.size != 0:\n",
        "        vector = np.mean(word_vectors, axis=0)\n",
        "\n",
        "    return vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "FEpFpJsfUdA4",
      "metadata": {
        "id": "FEpFpJsfUdA4"
      },
      "outputs": [],
      "source": [
        "# compute vector embedding for all lines in data\n",
        "data_vectors = np.array([get_phrase_embedding(l) for l in data])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be0a2f4e",
      "metadata": {},
      "source": [
        "### Складываем наш датасет в базу"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "id": "56b621dc",
      "metadata": {},
      "outputs": [],
      "source": [
        "import faiss\n",
        "class MyDb:\n",
        "    def __init__(self, sentences, sentence_embedings):\n",
        "        self._dim = len(sentence_embedings[0])\n",
        "        self._faiss = faiss.IndexFlatL2(self._dim )\n",
        "        self._faiss.add(sentence_embedings)\n",
        "        self._sentences = sentences\n",
        "\n",
        "    def get_similar(self, query_embeddings, k=5):\n",
        "        result = []\n",
        "        if (len(query_embeddings) == 0) or (len(query_embeddings[0])==0):\n",
        "            raise Exception(\"query_embeddings должно быть списком векторов-запросов для поиска похожих\")\n",
        "        d, i = self._faiss.search(x= query_embeddings, k = k)\n",
        "        \n",
        "        for r in i:\n",
        "            r_sent = self._sentences[i]\n",
        "            result.append(r_sent)\n",
        "        return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "id": "c8d0d0b9",
      "metadata": {},
      "outputs": [],
      "source": [
        "MDB = MyDb(data, data_vectors)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9hlHZAJAL1qL",
      "metadata": {
        "id": "9hlHZAJAL1qL"
      },
      "source": [
        "## 3.4. Применение модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "id": "2jbRh4UuL1qP",
      "metadata": {
        "id": "2jbRh4UuL1qP"
      },
      "outputs": [],
      "source": [
        "def find_nearest(query, k=10):\n",
        "    emb = get_phrase_embedding(query)\n",
        "    result = MDB.get_similar(np.array([emb]), k)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "id": "130aad1f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([['Will Donald Trump destroy Donald Trump?\\n',\n",
              "         'How did Melania Trump meet Donald Trump?\\n',\n",
              "         'Is Donald trump a populist?\\n',\n",
              "         'Should the NRA withdraw its endorsement of Donald Trump?\\n',\n",
              "         'Why is Quora biased agaist Donald Trump.?\\n',\n",
              "         'Donald Trump: Does Donald Trump have misogynistic views?\\n',\n",
              "         'Is Donald Trump a blowhard?\\n',\n",
              "         'What did Ivanka Trump do at Wharton?\\n',\n",
              "         'Is Donald Trump a “Teflon candidate”?\\n',\n",
              "         'Why is Quora against Donald Trump?\\n']], dtype='<U1170')]"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "find_nearest(\"Who is Trump\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "524d0aa5",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
